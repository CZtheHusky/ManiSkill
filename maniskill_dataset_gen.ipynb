{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legacy_path = \"stack_cubes/images\"\n",
    "# import os\n",
    "# for filen in os.listdir(legacy_path):\n",
    "#     if filen.endswith(\".jpg\") and \"_\" in filen:\n",
    "#         os.remove(os.path.join(legacy_path, filen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:49<01:21,  1.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:51<01:20,  1.31s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minternvl_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ManiSkillTrajectoryDataset, InternVLPretrainDatasetGenerator\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mManiSkillTrajectoryDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mStackCube-v1/motionplanning/trajectory.rgb.pd_ee_delta_pose.physx_cpu.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuccess_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_episode_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/nfs3/caozhe/workspace/ManiSkill/internvl_eval/utils.py:65\u001b[0m, in \u001b[0;36mManiSkillTrajectoryDataset.__init__\u001b[0;34m(self, dataset_file, load_count, success_only, device, is_episode_dataset)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(load_count, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_episode_dataset:\n\u001b[0;32m---> 65\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_dataset_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuccess_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_dataset(load_count, success_only, device)\n",
      "File \u001b[0;32m/mnt/nfs3/caozhe/workspace/ManiSkill/internvl_eval/utils.py:88\u001b[0m, in \u001b[0;36mManiSkillTrajectoryDataset.load_dataset_episode\u001b[0;34m(self, load_count, success_only)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     87\u001b[0m trajectory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraj_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepisode_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 88\u001b[0m trajectory \u001b[38;5;241m=\u001b[39m \u001b[43mload_h5_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m eps_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(trajectory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# exclude the final observation as most learning workflows do not use it\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/nfs3/caozhe/workspace/ManiSkill/internvl_eval/utils.py:24\u001b[0m, in \u001b[0;36mload_h5_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         out[k] \u001b[38;5;241m=\u001b[39m data[k][:]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         out[k] \u001b[38;5;241m=\u001b[39m \u001b[43mload_h5_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/mnt/nfs3/caozhe/workspace/ManiSkill/internvl_eval/utils.py:24\u001b[0m, in \u001b[0;36mload_h5_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         out[k] \u001b[38;5;241m=\u001b[39m data[k][:]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         out[k] \u001b[38;5;241m=\u001b[39m \u001b[43mload_h5_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/mnt/nfs3/caozhe/workspace/ManiSkill/internvl_eval/utils.py:24\u001b[0m, in \u001b[0;36mload_h5_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         out[k] \u001b[38;5;241m=\u001b[39m data[k][:]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         out[k] \u001b[38;5;241m=\u001b[39m \u001b[43mload_h5_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/mnt/nfs3/caozhe/workspace/ManiSkill/internvl_eval/utils.py:22\u001b[0m, in \u001b[0;36mload_h5_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data[k], h5py\u001b[38;5;241m.\u001b[39mDataset):\n\u001b[0;32m---> 22\u001b[0m         out[k] \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m         out[k] \u001b[38;5;241m=\u001b[39m load_h5_data(data[k])\n",
      "File \u001b[0;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/mnt/nfs3/caozhe/miniconda3/envs/verl/lib/python3.10/site-packages/h5py/_hl/dataset.py:820\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from internvl_eval.utils import ManiSkillTrajectoryDataset, InternVLPretrainDatasetGenerator\n",
    "\n",
    "dataset = ManiSkillTrajectoryDataset(dataset_file=\"StackCube-v1/motionplanning/trajectory.rgb.pd_ee_delta_pose.physx_cpu.h5\", success_only=False, device=None, is_episode_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = InternVLPretrainDatasetGenerator(\n",
    "    dataset=dataset,\n",
    "    save_path=\"stack_cubes_horizon\",\n",
    "    horizon=4,\n",
    "    dual_camera=True,\n",
    "    )\n",
    "# generator.cal_statistics()\n",
    "generator.traj_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mani_skill.envs\n",
    "import gymnasium as gym\n",
    "from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Set to the GPU you want to use\n",
    "\n",
    "N = 256\n",
    "env = gym.make(\"PickCube-v1\", num_envs=N, reconfiguration_freq=None)\n",
    "env = ManiSkillVectorEnv(env, num_envs=N, ignore_terminations=False, auto_reset=True, record_metrics=True)\n",
    "env.action_space # shape (N, D)\n",
    "env.single_action_space # shape (D, )\n",
    "env.observation_space # shape (N, ...)\n",
    "env.single_observation_space # shape (...)\n",
    "env.reset()\n",
    "obs, rew, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "# obs (N, ...), rew (N, ), terminated (N, ), truncated (N, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([True, True, True, True], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([False, False, False, False], device='cuda:0')\n",
      "tensor([False, False, False, False], device='cuda:0') tensor([True, True, True, True], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import mani_skill.envs\n",
    "import gymnasium as gym\n",
    "from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv\n",
    "N = 4\n",
    "env = gym.make(\"PickCube-v1\", num_envs=N, max_episode_steps=50)\n",
    "env = ManiSkillVectorEnv(env, auto_reset=True, ignore_terminations=False)\n",
    "env.action_space # shape (N, D)\n",
    "env.single_action_space # shape (D, )\n",
    "env.observation_space # shape (N, ...)\n",
    "env.single_observation_space # shape (...)\n",
    "env.reset()\n",
    "for i in range(100):\n",
    "    obs, rew, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    print(terminated, truncated)\n",
    "# obs (N, ...), rew (N, ), terminated (N, ), truncated (N, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs_68/caozhe/miniconda3/envs/verl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/nfs_68/caozhe/miniconda3/envs/verl/lib/python3.10/site-packages/sapien/_vulkan_tricks.py:21: UserWarning: Failed to find system libvulkan. Fallback to SAPIEN builtin libvulkan.\n",
      "  warn(\"Failed to find system libvulkan. Fallback to SAPIEN builtin libvulkan.\")\n",
      "/mnt/nfs_68/caozhe/miniconda3/envs/verl/lib/python3.10/site-packages/sapien/_vulkan_tricks.py:37: UserWarning: Failed to find Vulkan ICD file. This is probably due to an incorrect or partial installation of the NVIDIA driver. SAPIEN will attempt to provide an ICD file anyway but it may not work.\n",
      "  warn(\n",
      "/mnt/nfs_68/caozhe/miniconda3/envs/verl/lib/python3.10/site-packages/torch/random.py:187: UserWarning: CUDA reports that you have 8 available devices, and you have used fork_rng without explicitly specifying which devices are being used. For safety, we initialize *every* CUDA device by default, which can be quite slow if you have a lot of CUDAs. If you know that you are only making use of a few CUDA devices, set the environment variable CUDA_VISIBLE_DEVICES or the 'devices' keyword argument of fork_rng with the set of devices you are actually using. For example, if you are using CPU only, set device.upper()_VISIBLE_DEVICES= or devices=[]; if you are using device 0 only, set CUDA_VISIBLE_DEVICES=0 or devices=[0].  To initialize all devices and suppress this warning, set the 'devices' keyword argument to `range(torch.cuda.device_count())`.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "step\n",
      "success_once_mean: 0.0\n",
      "return_mean: 7.305637359619141\n",
      "episode_len_mean: 150.0\n",
      "reward_mean: 0.048704247921705246\n",
      "success_at_end_mean: 0.0\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv\n",
    "env_id = \"PushCube-v1\"\n",
    "num_eval_envs = 64\n",
    "env_kwargs = dict(obs_mode=\"state\") # modify your env_kwargs here\n",
    "eval_envs = gym.make(env_id, num_envs=num_eval_envs, reconfiguration_freq=1, **env_kwargs, max_episode_steps=150)\n",
    "# add any other wrappers here\n",
    "eval_envs = ManiSkillVectorEnv(eval_envs, ignore_terminations=True, record_metrics=True)\n",
    "\n",
    "# evaluation loop, which will record metrics for complete episodes only\n",
    "obs, _ = eval_envs.reset(seed=0)\n",
    "eval_metrics = defaultdict(list)\n",
    "for _ in range(450):\n",
    "    action = eval_envs.action_space.sample() # replace with your policy action\n",
    "    obs, rew, terminated, truncated, info = eval_envs.step(action)\n",
    "    # note as there are no partial resets, truncated is True for all environments at the same time\n",
    "    print(\"step\")\n",
    "    if truncated.any():\n",
    "        for k, v in info[\"final_info\"][\"episode\"].items():\n",
    "            eval_metrics[k].append(v.float())\n",
    "for k in eval_metrics.keys():\n",
    "    print(f\"{k}_mean: {torch.mean(torch.stack(eval_metrics[k])).item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success_once_mean: 0.0\n",
      "return_mean: 7.305637359619141\n",
      "episode_len_mean: 150.0\n",
      "reward_mean: 0.048704247921705246\n",
      "success_at_end_mean: 0.0\n"
     ]
    }
   ],
   "source": [
    "for k, v in eval_metrics.items():\n",
    "    print(f\"{k}_mean: {torch.mean(torch.stack(v)).item()}\")\n",
    "    eval_metrics[k] = torch.stack(v).cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics[k] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing video: ./test_save/0_0_0_150_False.mp4, Num steps: 150, Success: False\n",
      "Writing video: ./test_save/1_1_0_150_False.mp4, Num steps: 150, Success: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (480, 529) to (480, 544) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 0 done with reward 0.0027087628841400146, num dones: 16\n",
      "Environment 1 done with reward 0.018450289964675903, num dones: 15\n",
      "Writing video: ./test_save/2_0_1_150_False.mp4, Num steps: 150, Success: False\n",
      "Writing video: ./test_save/3_1_1_150_False.mp4, Num steps: 150, Success: False\n",
      "Environment 0 done with reward 0.0006744414567947388, num dones: 14\n",
      "Environment 1 done with reward 0.007344335317611694, num dones: 13\n",
      "Writing video: ./test_save/4_0_2_150_False.mp4, Num steps: 150, Success: False\n",
      "Writing video: ./test_save/5_1_2_150_False.mp4, Num steps: 150, Success: False\n",
      "Environment 0 done with reward 0.0005099326372146606, num dones: 12\n",
      "Environment 1 done with reward 0.01807159185409546, num dones: 11\n",
      "Writing video: ./test_save/6_0_3_150_False.mp4, Num steps: 150, Success: False\n",
      "Writing video: ./test_save/7_1_3_150_False.mp4, Num steps: 150, Success: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (480, 529) to (480, 544) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (480, 529) to (480, 544) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 0 done with reward 0.009738549590110779, num dones: 10\n",
      "Environment 1 done with reward 0.002504289150238037, num dones: 9\n",
      "Writing video: ./test_save/8_0_4_150_False.mp4, Num steps: 150, Success: False\n",
      "Writing video: ./test_save/9_1_4_150_False.mp4, Num steps: 150, Success: False\n",
      "Environment 0 done with reward 0.0008889734745025635, num dones: 8\n",
      "Environment 1 done with reward 0.0012055039405822754, num dones: 7\n",
      "Writing video: ./test_save/10_0_5_150_False.mp4, Num steps: 150, Success: False\n",
      "Writing video: ./test_save/11_1_5_150_False.mp4, Num steps: 150, Success: False\n",
      "Environment 0 done with reward 0.004766255617141724, num dones: 6\n",
      "Environment 1 done with reward 6.490945816040039e-05, num dones: 5\n",
      "Writing video: ./test_save/12_0_6_150_False.mp4, Num steps: 150, Success: False\n",
      "Writing video: ./test_save/13_1_6_150_False.mp4, Num steps: 150, Success: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (480, 529) to (480, 544) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (480, 529) to (480, 544) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 0 done with reward 0.003990381956100464, num dones: 4\n",
      "Environment 1 done with reward 0.005703866481781006, num dones: 3\n",
      "Writing video: ./test_save/14_0_7_150_False.mp4, Num steps: 150, Success: False\n",
      "Writing video: ./test_save/15_1_7_150_False.mp4, Num steps: 150, Success: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (480, 529) to (480, 544) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n",
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (480, 529) to (480, 544) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment 0 done with reward 0.049762338399887085, num dones: 2\n",
      "Environment 1 done with reward 0.010378226637840271, num dones: 1\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import mani_skill.envs\n",
    "from mani_skill.utils.wrappers.gymnasium import CPUGymWrapper\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from mani_skill.vector.wrappers.gymnasium import ManiSkillVectorEnv\n",
    "\n",
    "num_envs = 2\n",
    "env = gym.make(\n",
    "    \"StackCube-v1\", # there are more tasks e.g. \"PushCube-v1\", \"PegInsertionSide-v1\", ...\n",
    "    num_envs=num_envs,\n",
    "    obs_mode=\"rgb\", # there is also \"state_dict\", \"rgbd\", ...\n",
    "    control_mode=\"pd_ee_delta_pose\", # there is also \"pd_joint_delta_pos\", ...\n",
    "    sensor_configs={'height': 480, 'width': 480}, # camera configs\n",
    "    max_episode_steps=150,\n",
    ")\n",
    "env = ManiSkillVectorEnv(env, auto_reset=True, ignore_terminations=False)\n",
    "# print(\"Observation space\", env.observation_space)\n",
    "# print(\"Action space\", env.action_space)\n",
    "# env = CPUGymWrapper(env)  # wrap to use CPU for rendering\n",
    "obs, _ = env.reset(seed=0) # reset with a seed for determinism\n",
    "last_obs = obs\n",
    "num_dones = 16\n",
    "from internvl_eval.InternVL_eval_agent import VideoRecorder\n",
    "recorder = VideoRecorder(\n",
    "    save_path=\"./test_save\",\n",
    "    fps=30,\n",
    "    num_envs=num_envs,\n",
    ")\n",
    "while num_dones > 0:\n",
    "    actions = env.action_space.sample()  # sample random actions\n",
    "    obs, reward, terminated, truncated, info = env.step(actions)  # step with\n",
    "    is_terminals = np.logical_or(terminated.cpu().numpy(), truncated.cpu().numpy())\n",
    "    recorder.append_obs(last_obs, info['success'].cpu().numpy(), is_terminals, actions)\n",
    "    last_obs = obs\n",
    "    done_env_ids = np.where(is_terminals)[0]\n",
    "    if len(done_env_ids) > 0:\n",
    "        obs, _ = env.reset(options={\"env_idx\": done_env_ids, \"reconfigure\": True})  # reset the environments that are done\n",
    "        last_obs = obs\n",
    "    for env_id in done_env_ids:\n",
    "        print(f\"Environment {env_id} done with reward {reward[env_id]}, num dones: {num_dones}\")\n",
    "        num_dones -= 1\n",
    "# done = False\n",
    "# Image.fromarray(obs[\"sensor_data\"]['base_camera']['rgb']).show()  # show the first environment's RGB observation\n",
    "# while not done:\n",
    "#     action = env.action_space.sample()\n",
    "#     obs, reward, terminated, truncated, info = env.step(action)\n",
    "#     done = terminated or truncated\n",
    "#     # env.render()  # a display is required to render\n",
    "# env.close()\n",
    "\n",
    "\n",
    "# python -m mani_skill.trajectory.replay_trajectory --traj_path demos/StackCube-v1/motionplanning/trajectory.h5 --obs_mode rgb --target_control_mode pd_ee_delta_pose --verbose --save_traj --max_retry 2 --reward_mode 'sparse' --record_rewards --num_envs 32 --count 100\n",
    "# python -m mani_skill.trajectory.replay_trajectory --traj_path demos/StackCube-v1/rl/trajectory.none.pd_ee_delta_pose.physx_cuda.h5 --obs_mode rgb --target_control_mode pd_ee_delta_pose --verbose --save_traj --max_retry 2 --reward_mode 'sparse' --record_rewards --num_envs 32 --count 300\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=0 python train_rgbd.py --env-id StackCube-v1     --demo-path demos/StackCube-v1/motionplanning/trajectory.rgb.pd_ee_delta_pose.physx_cpu.h5     --control-mode \"pd_ee_delta_pose\" --sim-backend \"physx_cpu\" --num-demos 100 --max_episode_steps 200     --total_iters 100000 --obs-mode \"rgb\"     --exp-name diffusion_policy-StackCube-v1-rgb-100_motionplanning_demos-1     --demo_type=motionplanning --track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "ds_json_path = \"ManiSkill_Demonstrations/demos/PickCube-v1/teleop/trajectory.json\"\n",
    "with open(ds_json_path, \"r\") as f:\n",
    "    env_info = json.load(f)\n",
    "env = gym.make(env_info[\"env_id\"], **env_info[\"env_kwargs\"])\n",
    "episode = env_info[\"episodes\"][0] # picks the first\n",
    "env.reset(**episode[\"reset_kwargs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/nfs3/caozhe/miniconda3/envs/verl/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/mnt/nfs3/caozhe/miniconda3/envs/verl/lib/python3.10/site-packages/sapien/_vulkan_tricks.py:21: UserWarning: Failed to find system libvulkan. Fallback to SAPIEN builtin libvulkan.\n",
      "  warn(\"Failed to find system libvulkan. Fallback to SAPIEN builtin libvulkan.\")\n",
      "/mnt/nfs3/caozhe/miniconda3/envs/verl/lib/python3.10/site-packages/sapien/_vulkan_tricks.py:37: UserWarning: Failed to find Vulkan ICD file. This is probably due to an incorrect or partial installation of the NVIDIA driver. SAPIEN will attempt to provide an ICD file anyway but it may not work.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Union\n",
    "import h5py\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from mani_skill.utils.io_utils import load_json\n",
    "from mani_skill.utils import sapien_utils\n",
    "from mani_skill.utils import common\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def load_h5_data(data):\n",
    "    out = dict()\n",
    "    for k in data.keys():\n",
    "        if isinstance(data[k], h5py.Dataset):\n",
    "            out[k] = data[k][:]\n",
    "        else:\n",
    "            out[k] = load_h5_data(data[k])\n",
    "    return out\n",
    "\n",
    "def to_tensors(x, device=None):\n",
    "    \"\"\"\n",
    "    Converts numpy arrays or dicts of numpy arrays to torch tensors.\n",
    "    If device is specified, moves the tensors to that device.\n",
    "    \"\"\"\n",
    "    if isinstance(x, dict):\n",
    "        return {k: to_tensors(v, device) for k, v in x.items()}\n",
    "    elif isinstance(x, np.ndarray) and device is not None:\n",
    "        tensor = torch.as_tensor(x).to(device)\n",
    "        return tensor\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "class ManiSkillTrajectoryDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A general torch Dataset you can drop in and use immediately with just about any trajectory .h5 data generated from ManiSkill.\n",
    "    This class simply is a simple starter code to load trajectory data easily, but does not do any data transformation or anything\n",
    "    advanced. We recommend you to copy this code directly and modify it for more advanced use cases\n",
    "\n",
    "    Args:\n",
    "        dataset_file (str): path to the .h5 file containing the data you want to load\n",
    "        load_count (int): the number of trajectories from the dataset to load into memory. If -1, will load all into memory\n",
    "        success_only (bool): whether to skip trajectories that are not successful in the end. Default is false\n",
    "        device: The location to save data to. If None will store as numpy (the default), otherwise will move data to that device\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset_file: str, load_count=-1, success_only: bool = False, device = None) -> None:\n",
    "        self.dataset_file = dataset_file\n",
    "        self.device = device\n",
    "        self.data = h5py.File(dataset_file, \"r\")\n",
    "        json_path = dataset_file.replace(\".h5\", \".json\")\n",
    "        self.json_data = load_json(json_path)\n",
    "        self.episodes = self.json_data[\"episodes\"]\n",
    "        self.env_info = self.json_data[\"env_info\"]\n",
    "        self.env_id = self.env_info[\"env_id\"]\n",
    "        self.env_kwargs = self.env_info[\"env_kwargs\"]\n",
    "        if isinstance(load_count, int):\n",
    "            self.load_dataset(load_count, success_only, device)\n",
    "        else:\n",
    "            pass    \n",
    "        \n",
    "    def load_dataset(self, load_count, success_only, device):\n",
    "        self.obs = None\n",
    "        self.actions = []\n",
    "        self.terminated = []\n",
    "        self.truncated = []\n",
    "        self.success, self.fail, self.rewards = None, None, None\n",
    "        if load_count == -1:\n",
    "            load_count = len(self.episodes)\n",
    "        for eps_id in tqdm(range(load_count)):\n",
    "            eps = self.episodes[eps_id]\n",
    "            if success_only: \n",
    "                assert \"success\" in eps, \"episodes in this dataset do not have the success attribute, cannot load dataset with success_only=True\"\n",
    "                if not eps[\"success\"]:\n",
    "                    continue\n",
    "            trajectory = self.data[f\"traj_{eps['episode_id']}\"]\n",
    "            trajectory = load_h5_data(trajectory)\n",
    "            eps_len = len(trajectory[\"actions\"])\n",
    "            \n",
    "            # exclude the final observation as most learning workflows do not use it\n",
    "            obs = common.index_dict_array(trajectory[\"obs\"], slice(eps_len))\n",
    "            if eps_id == 0:\n",
    "                self.obs = obs\n",
    "            else:\n",
    "                self.obs = common.append_dict_array(self.obs, obs)\n",
    "\n",
    "            self.actions.append(trajectory[\"actions\"])\n",
    "            self.terminated.append(trajectory[\"terminated\"])\n",
    "            self.truncated.append(trajectory[\"truncated\"])\n",
    "\n",
    "            # handle data that might optionally be in the trajectory\n",
    "            if \"rewards\" in trajectory:\n",
    "                if self.rewards is None:\n",
    "                    self.rewards = [trajectory[\"rewards\"]]\n",
    "                else:\n",
    "                    self.rewards.append(trajectory[\"rewards\"])\n",
    "            if \"success\" in trajectory:\n",
    "                if self.success is None:\n",
    "                    self.success = [trajectory[\"success\"]]\n",
    "                else:\n",
    "                    self.success.append(trajectory[\"success\"])\n",
    "            if \"fail\" in trajectory:\n",
    "                if self.fail is None:\n",
    "                    self.fail = [trajectory[\"fail\"]]\n",
    "                else:\n",
    "                    self.fail.append(trajectory[\"fail\"])\n",
    "\n",
    "        self.actions = np.vstack(self.actions)\n",
    "        self.terminated = np.concatenate(self.terminated)\n",
    "        self.truncated = np.concatenate(self.truncated)\n",
    "        \n",
    "        if self.rewards is not None:\n",
    "            self.rewards = np.concatenate(self.rewards)\n",
    "        if self.success is not None:\n",
    "            self.success = np.concatenate(self.success)\n",
    "        if self.fail is not None:\n",
    "            self.fail = np.concatenate(self.fail)\n",
    "\n",
    "        def remove_np_uint16(x: Union[np.ndarray, dict]):\n",
    "            if isinstance(x, dict):\n",
    "                for k in x.keys():\n",
    "                    x[k] = remove_np_uint16(x[k])\n",
    "                return x\n",
    "            else:\n",
    "                if x.dtype == np.uint16:\n",
    "                    return x.astype(np.int32)\n",
    "                return x\n",
    "        \n",
    "        # uint16 dtype is used to conserve disk space and memory\n",
    "        # you can optimize this dataset code to keep it as uint16 and process that\n",
    "        # dtype of data yourself. for simplicity we simply cast to a int32 so\n",
    "        # it can automatically be converted to torch tensors without complaint\n",
    "        self.obs = remove_np_uint16(self.obs)\n",
    "\n",
    "        if device is not None:\n",
    "            self.actions = to_tensors(self.actions, device=device)\n",
    "            self.obs = to_tensors(self.obs, device=device)\n",
    "            self.terminated = to_tensors(self.terminated, device=device)\n",
    "            self.truncated = to_tensors(self.truncated, device=device)\n",
    "            if self.rewards is not None:\n",
    "                self.rewards = to_tensors(self.rewards, device=device)\n",
    "            if self.success is not None:\n",
    "                self.success = to_tensors(self.terminated, device=device)\n",
    "            if self.fail is not None:\n",
    "                self.fail = to_tensors(self.truncated, device=device)\n",
    "                \n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.actions)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        action = to_tensors(self.actions[idx], device=self.device)\n",
    "        obs = common.index_dict_array(self.obs, idx, inplace=False)\n",
    "\n",
    "        res = dict(\n",
    "            obs=obs,\n",
    "            action=action,\n",
    "            terminated=self.terminated[idx],\n",
    "            truncated=self.truncated[idx],\n",
    "        )\n",
    "        if self.rewards is not None:\n",
    "            res.update(reward=self.rewards[idx])\n",
    "        if self.success is not None:\n",
    "            res.update(success=self.success[idx])\n",
    "        if self.fail is not None:\n",
    "            res.update(fail=self.fail[idx])\n",
    "        return res\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InternVLPretrainDatasetGenerator:\n",
    "    def __init__(self, dataset: ManiSkillTrajectoryDataset, save_path: str):\n",
    "        \"\"\"\n",
    "        Initializes the dataset generator for InternVL pretraining.\n",
    "\n",
    "        Args:\n",
    "            dataset_path (str): Path to the dataset file.\n",
    "            load_count (int): Number of trajectories to load. If -1, loads all.\n",
    "            success_only (bool): Whether to filter for successful trajectories only.\n",
    "            device: Device to load data onto (e.g., 'cpu', 'cuda').\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.save_path = save_path\n",
    "        self.img_save_path = os.path.join(save_path, \"images\")\n",
    "        os.makedirs(self.img_save_path, exist_ok=True)\n",
    "        rng = np.random.default_rng(0)\n",
    "        val_ids = rng.choice(len(self.dataset), size=len(self.dataset) // 20, replace=False)\n",
    "        self.val_ids = set(val_ids)\n",
    "        img_path_prefix = \"/home/caozhe/workspace/ManiSkill/\"\n",
    "        self.img_path_save = img_path_prefix + self.img_save_path\n",
    "        if \"StackCube-v1\" in self.dataset.env_id:\n",
    "            self.instruction = \"stack the red cube on top of the green one\"\n",
    "        \n",
    "    def cal_statistics(self):\n",
    "        statistics = {\n",
    "            'action': {},\n",
    "            'qpos': {},\n",
    "            'tcp_pose': {}\n",
    "        }\n",
    "        all_collections = {\n",
    "            'action': [],\n",
    "            'qpos': [],\n",
    "            'tcp_pose': []\n",
    "        }\n",
    "        for data in self.dataset:\n",
    "            # camera = data[\"obs\"]['sensor_data'][\"base_camera\"][\"rgb\"]\n",
    "            qpos = data[\"obs\"][\"agent\"][\"qpos\"]\n",
    "            tcp_pose = data[\"obs\"][\"extra\"][\"tcp_pose\"]\n",
    "            action = data[\"action\"]\n",
    "            all_collections['action'].append(action)\n",
    "            all_collections['qpos'].append(qpos)\n",
    "            all_collections['tcp_pose'].append(tcp_pose)\n",
    "\n",
    "        for key in statistics.keys():\n",
    "            all_data = all_collections[key]\n",
    "            statistics[key]['mean'] = np.mean(all_data, axis=0).tolist()\n",
    "            statistics[key]['std'] = np.std(all_data, axis=0).tolist()\n",
    "            statistics[key]['min'] = np.min(all_data, axis=0).tolist()\n",
    "            statistics[key]['max'] = np.max(all_data, axis=0).tolist()\n",
    "        # print(\"Statistics calculated:\", statistics)\n",
    "        self.statistics = statistics\n",
    "        with open(os.path.join(self.save_path, 'statistics.json'), 'w') as f:\n",
    "            json.dump(statistics, f, indent=4)\n",
    "        self.rescale_array = {\n",
    "            'action': np.array([1000] * (len(statistics['action']['max']) - 1) + [1]),\n",
    "            'qpos': np.array([1000] * len(statistics['qpos']['max'])),\n",
    "            'tcp_pose': np.array([1000] * len(statistics['tcp_pose']['max']))\n",
    "        }\n",
    "        # for key in statistics.keys():\n",
    "        #     for idx, (max_v, min_v) in enumerate(zip(statistics[key]['max'], statistics[key]['min'])):\n",
    "        #         if abs(max_v) > 1 or abs(min_v) > 1 and self.rescale_array[key][idx] != 1:\n",
    "        #             self.rescale_array[key][idx] = 100\n",
    "     \n",
    "    def rescale(self, data, key):\n",
    "        _tmp_data = np.round(data * self.rescale_array[key]).astype(np.int32)\n",
    "        if key == \"action\":\n",
    "            _tmp_data = np.clip(-999, 999, _tmp_data)\n",
    "        return _tmp_data\n",
    "        \n",
    "    \n",
    "    def generation(self):\n",
    "        json_infos = []\n",
    "        val_infos = []\n",
    "        for idx, data in enumerate(self.dataset):\n",
    "            data_dict = {}\n",
    "            camera = data[\"obs\"]['sensor_data'][\"base_camera\"][\"rgb\"]\n",
    "            hand_camera = data[\"obs\"]['sensor_data'][\"hand_camera\"][\"rgb\"]\n",
    "            qpos = data[\"obs\"][\"agent\"][\"qpos\"]\n",
    "            tcp_pose = data[\"obs\"][\"extra\"][\"tcp_pose\"]\n",
    "            action = data[\"action\"]\n",
    "            rescaled_qpos = self.rescale(qpos, 'qpos')\n",
    "            rescaled_tcp_pose = self.rescale(tcp_pose, 'tcp_pose')\n",
    "            rescaled_action = self.rescale(action, 'action')\n",
    "            if not os.path.exists(os.path.join(self.img_save_path, f\"{idx}.jpg\")):\n",
    "                img = Image.fromarray(camera)\n",
    "                img.save(os.path.join(self.img_save_path, f\"{idx}.jpg\"))\n",
    "            if not os.path.exists(os.path.join(self.img_save_path, f\"{idx}_hand.jpg\")):\n",
    "                hand_img = Image.fromarray(hand_camera)\n",
    "                hand_img.save(os.path.join(self.img_save_path, f\"{idx}_hand.jpg\"))\n",
    "            \n",
    "            query = f\"The current position state of the robotic arm's end gripper is as follows: {{Joint_0: {rescaled_qpos[0]}, Joint_1: {rescaled_qpos[1]}, Joint_2: {rescaled_qpos[2]}, Joint_3: {rescaled_qpos[3]}, Joint_4: {rescaled_qpos[4]}, Joint_5: {rescaled_qpos[5]}, Joint_6: {rescaled_qpos[6]}, Joint_7: {rescaled_qpos[7]}, Joint_8: {rescaled_qpos[8]}}}. What action should the robot take to get better completion of instruction: {self.instruction}?\"\n",
    "            action_str = \" \".join([f\"{str(int(a))}\" for a in rescaled_action])\n",
    "            action_str = '{' + action_str + '}'\n",
    "            data_dict['query'] = query\n",
    "            data_dict['response'] = action_str\n",
    "            data_dict['images'] = [os.path.join(self.img_path_save, f\"{idx}.jpg\"), os.path.join(self.img_path_save, f\"{idx}_hand.jpg\")]\n",
    "            if idx in self.val_ids:\n",
    "                val_infos.append(data_dict)\n",
    "            else:\n",
    "                json_infos.append(data_dict)\n",
    "        with open(os.path.join(self.save_path, 'dualcam_dataset.json'), 'w') as f:\n",
    "            json.dump(json_infos, f, indent=4)\n",
    "        with open(os.path.join(self.save_path, 'val_dualcam_dataset.json'), 'w') as f:\n",
    "            json.dump(val_infos, f, indent=4)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small_dataset = ManiSkillTrajectoryDataset(dataset_file=\"ManiSkill_Demonstrations/demos/StackCube-v1/motionplanning/trajectory.rgb.pd_ee_delta_pose.physx_cpu.h5\", load_count=10, success_only=False, device=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minternvl_eval\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mInternVL_eval_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m video_writing, write_instruction_action, action_to_str\n",
      "File \u001b[0;32m/cpfs/user/caozhe/ManiSkill/internvl_eval/InternVL_eval_agent.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mT\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InterpolationMode\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "# from internvl_eval.InternVL_eval_agent import video_writing, write_instruction_action, action_to_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (960, 529) to (960, 544) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    }
   ],
   "source": [
    "# all_cameras = []\n",
    "# ep_r = 0\n",
    "# for data in small_dataset:\n",
    "#     success = data['success']\n",
    "#     reward = data['reward']\n",
    "#     ep_r += reward\n",
    "#     terminated = data['terminated']\n",
    "#     truncated = data['truncated']\n",
    "#     action = data['action']\n",
    "#     camera = data['obs']['sensor_data']['base_camera']['rgb']\n",
    "#     wrist_cam = data['obs']['sensor_data']['hand_camera']['rgb']\n",
    "#     camera = np.concatenate([camera, wrist_cam], axis=1)  # concatenate the two cameras\n",
    "#     instruction = f\"R: {np.round(reward, 3)} EPR: {np.round(ep_r, 3)} Te: {terminated} Tr: {truncated} Su: {success}\"\n",
    "#     action = f\"A: {action_to_str(action, 3)}\"\n",
    "#     camera = write_instruction_action(instruction, camera, action)\n",
    "#     all_cameras.append(camera)\n",
    "#     if terminated or truncated:\n",
    "#         ep_r = 0\n",
    "# video_writing([all_cameras], \"./test_video.mp4\", fps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ManiSkillTrajectoryDataset(dataset_file=\"demos/StackCube-v1/motionplanning/trajectory.rgb.pd_ee_delta_pose.physx_cpu.h5\", success_only=False, device=None)\n",
    "generator = InternVLPretrainDatasetGenerator(\n",
    "    dataset=dataset,\n",
    "    save_path=\"stack_cubes\"\n",
    "    )\n",
    "generator.cal_statistics()\n",
    "generator.generation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
